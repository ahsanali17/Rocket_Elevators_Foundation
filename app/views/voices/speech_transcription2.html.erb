<body style="font-family:'Helvetica Neue',Helvetica,Arial,sans-serif; font-size:13px;">
  
  <div id="content" style="display:none">
    <table width="100%">
      <tr>
        <td></td>
        <td><h1 style="font-weight:500;">Rocket Elevators Speech to Text</h1></td>
      </tr>

      <tr>
        <!-- This is where the subscription id from Azure Cognitive Service is put. This field is hidden -->
        <td><input id="subscriptionKey" type="hidden" size="40" value="45dde55e10444d3eae10a478030f15f1"></td>
      </tr>

      <tr>
        <!-- This is where the region is setup. Needs to be set to westus as the service is only available on that region. This field is hidden -->
        <td><input id="serviceRegion" type="hidden" size="40" value="westus"></td>
      </tr>
      <tr>
        <!-- This is where the user will select the appropriate language based on the file language -->
        <td align="right">Source Language</td>
        <td><select id="languageSourceOptions">
          <option value="en-CA">English - CA</option>
          <option value="fr-CA">French - CA</option>
        </select></td>
      </tr>

      <tr>
        <!-- This is where the user select the file that will be converted to text. WAV files only -->
        <td align="right">File to Recognize</td>
        <td>
          <input type="file" id="filePicker" accept=".wav" />
        </td>
      </tr>
      <tr>
        <td></td>

        <!-- This is the button that initiates the transcription -->
        <td><button id="startRecognizeOnceAsyncButton">Start recognition</button></td>
      </tr>
      
      <tr>
        <!-- This is where the result of the transcription will be displayed -->
        <td align="right" valign="top">Results</td>
        <td><textarea id="phraseDiv" style="display: inline-block;width:500px;height:200px"></textarea></td>
      </tr>
    </table>
  </div>


  <!-- This is where all the script from Azure are stored -->

  <!-- Speech SDK reference sdk. -->
  <script src="microsoft.cognitiveservices.speech.sdk.bundle.js"></script>

  <!-- Speech SDK Authorization token -->
  <script>
  var authorizationEndpoint = "token.php";

  function RequestAuthorizationToken() {
    if (authorizationEndpoint) {
      var a = new XMLHttpRequest();
      a.open("GET", authorizationEndpoint);
      a.setRequestHeader("Content-Type", "application/x-www-form-urlencoded");
      a.send("");
      a.onload = function() {
          var token = JSON.parse(atob(this.responseText.split(".")[1]));
          serviceRegion.value = token.region;
          authorizationToken = this.responseText;
          subscriptionKey.disabled = true;
          subscriptionKey.value = "using authorization token (hit F5 to refresh)";
          console.log("Got an authorization token: " + token);
      }
    }
  }
  </script>
  <!-- Speech SDK USAGE -->
  <script>
    // status fields and start button in UI
    var phraseDiv;
    var startRecognizeOnceAsyncButton;
    var filePicker, audioFile;

    // subscription key and region for speech services.
    var subscriptionKey, serviceRegion;
    var authorizationToken;
    var SpeechSDK;
    var recognizer;

    document.addEventListener("DOMContentLoaded", function () {
      startRecognizeOnceAsyncButton = document.getElementById("startRecognizeOnceAsyncButton");
      subscriptionKey = document.getElementById("subscriptionKey");
      serviceRegion = document.getElementById("serviceRegion");
      phraseDiv = document.getElementById("phraseDiv");
      filePicker = document.getElementById("filePicker");
      filePicker.addEventListener("change", function () {
          audioFile = filePicker.files[0];
          startRecognizeOnceAsyncButton.disabled = false;
      });

      startRecognizeOnceAsyncButton.addEventListener("click", function () {
        startRecognizeOnceAsyncButton.disabled = true;
        phraseDiv.innerHTML = "";

        // if we got an authorization token, use the token. Otherwise use the provided subscription key
        var speechConfig;
        if (authorizationToken) {
          speechConfig = SpeechSDK.SpeechConfig.fromAuthorizationToken(authorizationToken, serviceRegion.value);
        } else {
          if (subscriptionKey.value === "" || subscriptionKey.value === "subscription") {
            alert("Please enter your Microsoft Cognitive Services Speech subscription key!");
            return;
          }
          speechConfig = SpeechSDK.SpeechConfig.fromSubscription(subscriptionKey.value, serviceRegion.value);
        }

        speechConfig.speechRecognitionLanguage = languageSourceOptions.value;
        var audioConfig  = SpeechSDK.AudioConfig.fromWavFileInput(audioFile);
        recognizer = new SpeechSDK.SpeechRecognizer(speechConfig, audioConfig);

        recognizer.recognizeOnceAsync(
          function (result) {
            startRecognizeOnceAsyncButton.disabled = false;
            phraseDiv.innerHTML += result.text;
            window.console.log(result);

            recognizer.close();
            recognizer = undefined;
          },
          function (err) {
            startRecognizeOnceAsyncButton.disabled = false;
            phraseDiv.innerHTML += err;
            window.console.log(err);

            recognizer.close();
            recognizer = undefined;
          });
      });

      if (!!window.SpeechSDK) {
        SpeechSDK = window.SpeechSDK;
        startRecognizeOnceAsyncButton.disabled = false;

        document.getElementById('content').style.display = 'block';
        document.getElementById('warning').style.display = 'none';

        // in case we have a function for getting an authorization token, call it.
        if (typeof RequestAuthorizationToken === "function") {
            RequestAuthorizationToken();
        }
      }
    });
  </script>
</body>
</html>